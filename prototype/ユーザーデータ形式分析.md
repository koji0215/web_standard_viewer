# ユーザーデータ形式の分析とSQLite互換性評価

## 概要

ユーザー提供のJSONファイル（`w12_tsdata_example.json`、`asassn_tsdata_example.json`）を分析し、
SQLiteでの使用可能性と、大規模データ（10,000個以上）での効率的な構成について評価します。

---

## 1. 提供されたデータ形式の分析

### 1.1 NEOWISE データ (`w12_tsdata_example.json`)

**構造:**
```json
{
  "mjd": {"0": 56916.805, "1": 57099.455, ...},
  "mag_mean": {"0": 8.3305, "1": 8.3362, ...},
  "mag_lim": {"0": 0.00279, "1": 0.00292, ...},
  "band": {"0": "W1", "1": "W1", ...}
}
```

**データ内容:**
| フィールド | 説明 | データ数 |
|-----------|------|---------|
| `mjd` | 修正ユリウス日 | 40個 |
| `mag_mean` | 平均等級 | 40個 |
| `mag_lim` | 等級誤差 | 40個 |
| `band` | バンド（W1/W2） | 40個 |

**形式の特徴:**
- Pandas DataFrameを `to_json(orient='dict')` で出力した形式
- キーが文字列インデックス（"0", "1", "2"...）
- W1とW2が同一配列内に混在

### 1.2 ASASSN データ (`asassn_tsdata_example.json`)

**構造:**
```json
{
  "mjd": {"0": 56776.033, "1": 56783.965, ...},
  "mag": {"0": 10.174, "1": 10.211, ...},
  "mag_err": {"0": 0.0011, "1": 0.0011, ...},
  "phot_filter": {"0": "V", "1": "V", ...}
}
```

**データ内容:**
| フィールド | 説明 | データ数 |
|-----------|------|---------|
| `mjd` | 修正ユリウス日 | 3,154個 |
| `mag` | 等級 | 3,154個 |
| `mag_err` | 等級誤差 | 3,154個 |
| `phot_filter` | バンド（V/g等） | 3,154個 |

---

## 2. SQLite互換性評価

### ✅ 結論: **互換性あり。変換可能**

現在の形式からSQLiteへの移行は可能ですが、**データ変換が必要**です。

### 2.1 必要な変換

#### 現在の形式（Pandas dict形式）
```json
{"mjd": {"0": 56916.8, "1": 57099.4}, "mag": {"0": 8.33, "1": 8.34}}
```

#### 推奨する形式（配列形式）
```json
{
  "source_id": "12345678",
  "ra": 123.456,
  "dec": -12.345,
  "observations": [
    {"mjd": 56916.8, "mag": 8.33, "mag_err": 0.003, "band": "W1"},
    {"mjd": 57099.4, "mag": 8.34, "mag_err": 0.003, "band": "W1"}
  ]
}
```

### 2.2 変換スクリプト例

```python
import json

def convert_neowise_format(input_json):
    """Pandas dict形式から標準配列形式に変換"""
    data = json.loads(input_json)
    
    observations = []
    for i in range(len(data['mjd'])):
        idx = str(i)
        observations.append({
            'mjd': data['mjd'][idx],
            'mag': data['mag_mean'][idx],
            'mag_err': data['mag_lim'][idx],
            'band': data['band'][idx]
        })
    
    return observations

def convert_asassn_format(input_json):
    """Pandas dict形式から標準配列形式に変換"""
    data = json.loads(input_json)
    
    observations = []
    for i in range(len(data['mjd'])):
        idx = str(i)
        observations.append({
            'mjd': data['mjd'][idx],
            'mag': data['mag'][idx],
            'mag_err': data['mag_err'][idx],
            'band': data['phot_filter'][idx]
        })
    
    return observations
```

---

## 3. 足りていない情報

### 3.1 必須: 天体識別子

**現状:** ❌ なし

**必要な情報:**
- `source_id`: 一意な天体識別子（Gaia SOURCE_ID推奨）
- このIDがないと、どのファイルがどの天体かわからない

**解決策:**
1. ファイル名に識別子を含める: `12345678.json`
2. JSON内に識別子を追加:
   ```json
   {
     "source_id": "12345678",
     "mjd": {...},
     ...
   }
   ```

### 3.2 推奨: 座標情報

**現状:** ❌ なし

**必要な情報:**
- `ra`: 赤経（度）
- `dec`: 赤緯（度）

**理由:**
- 座標検索（地図クリックで選択）に必要
- クロスマッチ確認に便利

### 3.3 推奨: メタデータ

**オプション情報:**
```json
{
  "source_id": "12345678",
  "ra": 123.456,
  "dec": -12.345,
  "allwise_id": "J123456.78-123456.7",  // AllWISE ID
  "gaia_id": "Gaia DR3 12345678",       // Gaia ID
  "num_observations": 40,               // 観測数
  "observations": [...]
}
```

---

## 4. 大規模データ（10,000個以上）向け推奨構成

### 4.1 ファイル構成

#### 推奨構成 A: 個別JSONファイル（シンプル）

```
data/
├── neowise/
│   ├── 12345678.json
│   ├── 23456789.json
│   └── ...（10,000ファイル）
├── asassn/
│   ├── 12345678.json
│   ├── 23456789.json
│   └── ...（10,000ファイル）
└── index.json  ← メタデータインデックス
```

**index.json の構造:**
```json
{
  "sources": [
    {
      "source_id": "12345678",
      "ra": 123.456,
      "dec": -12.345,
      "has_neowise": true,
      "has_asassn": true,
      "neowise_obs_count": 40,
      "asassn_obs_count": 3154
    }
  ]
}
```

**メリット:**
- ✅ 実装が簡単
- ✅ 個別ファイルアクセスが高速
- ✅ 部分的な更新が容易

**デメリット:**
- ❌ 10,000以上のファイル管理
- ❌ 座標検索が遅い（全件スキャン必要）

#### 推奨構成 B: SQLiteデータベース（高性能）

```
data/
└── lightcurves.db  ← 単一ファイル（〜180MB）
```

**メリット:**
- ✅ 単一ファイルで管理
- ✅ 座標検索が高速（インデックス使用）
- ✅ 複雑なクエリに対応
- ✅ ディスク使用量が30%削減

**デメリット:**
- ❌ セットアップがやや複雑
- ❌ 直接JSONとして使用不可

### 4.2 推奨: SQLiteスキーマ

```sql
-- メタデータテーブル
CREATE TABLE sources (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_id TEXT UNIQUE NOT NULL,
    ra REAL NOT NULL,
    dec REAL NOT NULL,
    allwise_id TEXT,
    gaia_id TEXT,
    neowise_obs_count INTEGER DEFAULT 0,
    asassn_obs_count INTEGER DEFAULT 0
);

-- インデックス
CREATE INDEX idx_source_id ON sources(source_id);
CREATE INDEX idx_ra ON sources(ra);
CREATE INDEX idx_dec ON sources(dec);

-- NEOWISE観測テーブル
CREATE TABLE neowise_observations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_id TEXT NOT NULL,
    mjd REAL NOT NULL,
    mag REAL,
    mag_err REAL,
    band TEXT,
    FOREIGN KEY (source_id) REFERENCES sources(source_id)
);

CREATE INDEX idx_neowise_source ON neowise_observations(source_id);

-- ASASSN観測テーブル
CREATE TABLE asassn_observations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_id TEXT NOT NULL,
    mjd REAL NOT NULL,
    mag REAL,
    mag_err REAL,
    band TEXT,
    FOREIGN KEY (source_id) REFERENCES sources(source_id)
);

CREATE INDEX idx_asassn_source ON asassn_observations(source_id);
```

### 4.3 データ投入スクリプト

```python
#!/usr/bin/env python3
"""
ユーザー形式のJSONからSQLiteへ変換するスクリプト
"""

import sqlite3
import json
from pathlib import Path
from tqdm import tqdm

def create_database(db_path):
    """データベースを作成"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # テーブル作成
    cursor.executescript('''
        CREATE TABLE IF NOT EXISTS sources (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            source_id TEXT UNIQUE NOT NULL,
            ra REAL,
            dec REAL,
            neowise_obs_count INTEGER DEFAULT 0,
            asassn_obs_count INTEGER DEFAULT 0
        );
        
        CREATE INDEX IF NOT EXISTS idx_source_id ON sources(source_id);
        
        CREATE TABLE IF NOT EXISTS neowise_observations (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            source_id TEXT NOT NULL,
            mjd REAL NOT NULL,
            mag REAL,
            mag_err REAL,
            band TEXT
        );
        
        CREATE INDEX IF NOT EXISTS idx_neowise_source ON neowise_observations(source_id);
        
        CREATE TABLE IF NOT EXISTS asassn_observations (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            source_id TEXT NOT NULL,
            mjd REAL NOT NULL,
            mag REAL,
            mag_err REAL,
            band TEXT
        );
        
        CREATE INDEX IF NOT EXISTS idx_asassn_source ON asassn_observations(source_id);
    ''')
    
    conn.commit()
    return conn

def import_neowise_json(conn, source_id, json_path, ra=None, dec=None):
    """NEOWISEのJSONファイルをインポート"""
    with open(json_path, 'r') as f:
        data = json.load(f)
    
    cursor = conn.cursor()
    
    # sourcesテーブルに追加（存在しない場合）
    cursor.execute('''
        INSERT OR IGNORE INTO sources (source_id, ra, dec)
        VALUES (?, ?, ?)
    ''', (source_id, ra, dec))
    
    # 観測データを変換・挿入
    observations = []
    for i in range(len(data['mjd'])):
        idx = str(i)
        observations.append((
            source_id,
            data['mjd'][idx],
            data['mag_mean'][idx],
            data['mag_lim'][idx],
            data['band'][idx]
        ))
    
    cursor.executemany('''
        INSERT INTO neowise_observations (source_id, mjd, mag, mag_err, band)
        VALUES (?, ?, ?, ?, ?)
    ''', observations)
    
    # 観測数を更新
    cursor.execute('''
        UPDATE sources SET neowise_obs_count = ? WHERE source_id = ?
    ''', (len(observations), source_id))
    
    conn.commit()
    return len(observations)

def import_asassn_json(conn, source_id, json_path, ra=None, dec=None):
    """ASASSNのJSONファイルをインポート"""
    with open(json_path, 'r') as f:
        data = json.load(f)
    
    cursor = conn.cursor()
    
    # sourcesテーブルに追加（存在しない場合）
    cursor.execute('''
        INSERT OR IGNORE INTO sources (source_id, ra, dec)
        VALUES (?, ?, ?)
    ''', (source_id, ra, dec))
    
    # 観測データを変換・挿入
    observations = []
    for i in range(len(data['mjd'])):
        idx = str(i)
        observations.append((
            source_id,
            data['mjd'][idx],
            data['mag'][idx],
            data['mag_err'][idx],
            data['phot_filter'][idx]
        ))
    
    cursor.executemany('''
        INSERT INTO asassn_observations (source_id, mjd, mag, mag_err, band)
        VALUES (?, ?, ?, ?, ?)
    ''', observations)
    
    # 観測数を更新
    cursor.execute('''
        UPDATE sources SET asassn_obs_count = ? WHERE source_id = ?
    ''', (len(observations), source_id))
    
    conn.commit()
    return len(observations)

# 使用例
if __name__ == "__main__":
    # データベース作成
    conn = create_database("lightcurves.db")
    
    # ファイルからインポート
    # source_idはファイル名から取得するか、別途マッピングが必要
    
    # 例: /tmp/w12_tsdata_example.json → source_id="example"
    import_neowise_json(conn, "example_star", "/tmp/w12_tsdata_example.json", ra=123.456, dec=-12.345)
    import_asassn_json(conn, "example_star", "/tmp/asassn_tsdata_example.json", ra=123.456, dec=-12.345)
    
    conn.close()
    print("Database created: lightcurves.db")
```

---

## 5. 推奨するJSONファイル形式

### 5.1 NEOWISE用（改良版）

**ファイル名:** `{source_id}_neowise.json`

```json
{
  "source_id": "12345678",
  "ra": 123.456789,
  "dec": -12.345678,
  "allwise_id": "J123456.78-123456.7",
  "num_observations": 40,
  "observations": [
    {"mjd": 56916.8050, "mag": 8.3305, "mag_err": 0.0028, "band": "W1"},
    {"mjd": 57099.4551, "mag": 8.3362, "mag_err": 0.0029, "band": "W1"},
    {"mjd": 56916.8142, "mag": 8.4234, "mag_err": 0.0025, "band": "W2"},
    ...
  ]
}
```

### 5.2 ASASSN用（改良版）

**ファイル名:** `{source_id}_asassn.json`

```json
{
  "source_id": "12345678",
  "ra": 123.456789,
  "dec": -12.345678,
  "gaia_id": "Gaia DR3 12345678",
  "num_observations": 3154,
  "observations": [
    {"mjd": 56776.0330, "mag": 10.1747, "mag_err": 0.0011, "band": "V"},
    {"mjd": 56783.9647, "mag": 10.2115, "mag_err": 0.0011, "band": "V"},
    ...
  ]
}
```

### 5.3 変換スクリプト（Pandas形式 → 推奨形式）

```python
#!/usr/bin/env python3
"""
Pandas dict形式から推奨JSON形式に変換
"""

import json
from pathlib import Path

def convert_neowise_to_standard(input_path, output_path, source_id, ra=None, dec=None):
    """NEOWISEデータを標準形式に変換"""
    with open(input_path, 'r') as f:
        data = json.load(f)
    
    observations = []
    for i in range(len(data['mjd'])):
        idx = str(i)
        observations.append({
            'mjd': data['mjd'][idx],
            'mag': data['mag_mean'][idx],
            'mag_err': data['mag_lim'][idx],
            'band': data['band'][idx]
        })
    
    result = {
        'source_id': source_id,
        'ra': ra,
        'dec': dec,
        'num_observations': len(observations),
        'observations': observations
    }
    
    with open(output_path, 'w') as f:
        json.dump(result, f, indent=2)
    
    return len(observations)

def convert_asassn_to_standard(input_path, output_path, source_id, ra=None, dec=None):
    """ASASSNデータを標準形式に変換"""
    with open(input_path, 'r') as f:
        data = json.load(f)
    
    observations = []
    for i in range(len(data['mjd'])):
        idx = str(i)
        observations.append({
            'mjd': data['mjd'][idx],
            'mag': data['mag'][idx],
            'mag_err': data['mag_err'][idx],
            'band': data['phot_filter'][idx]
        })
    
    result = {
        'source_id': source_id,
        'ra': ra,
        'dec': dec,
        'num_observations': len(observations),
        'observations': observations
    }
    
    with open(output_path, 'w') as f:
        json.dump(result, f, indent=2)
    
    return len(observations)

# 使用例
if __name__ == "__main__":
    # NEOWISE変換
    convert_neowise_to_standard(
        "/tmp/w12_tsdata_example.json",
        "12345678_neowise.json",
        source_id="12345678",
        ra=123.456,
        dec=-12.345
    )
    
    # ASASSN変換
    convert_asassn_to_standard(
        "/tmp/asassn_tsdata_example.json",
        "12345678_asassn.json",
        source_id="12345678",
        ra=123.456,
        dec=-12.345
    )
```

---

## 6. まとめ

### 6.1 現在のデータ形式について

| 項目 | 評価 |
|------|------|
| **SQLite互換性** | ✅ 変換可能 |
| **データ構造** | ⚠️ Pandas dict形式（変換推奨） |
| **天体識別子** | ❌ なし（必須で追加必要） |
| **座標情報** | ❌ なし（推奨で追加） |

### 6.2 推奨アクション

1. **天体識別子を追加**
   - ファイル名または JSON内に `source_id` を含める
   
2. **座標情報を追加**（推奨）
   - `ra`, `dec` を JSON に含める
   
3. **配列形式に変換**（推奨）
   - `observations: [...]` 形式が扱いやすい
   
4. **10,000個以上の場合はSQLiteへ移行**
   - 上記スキーマとスクリプトを使用

### 6.3 ファイル配置の推奨

```
prototype/
└── data/
    ├── neowise/
    │   ├── {source_id}.json  # 各天体のNEOWISEデータ
    │   └── ...
    ├── asassn/
    │   ├── {source_id}.json  # 各天体のASASSNデータ
    │   └── ...
    └── sources_index.json    # 全天体のメタデータインデックス
```

または

```
prototype/
└── data/
    └── lightcurves.db        # SQLiteデータベース（10,000個以上向け）
```

### 6.4 パフォーマンス見積もり（10,000天体）

| 方式 | ディスク | SOURCE ID検索 | 座標検索 |
|------|---------|--------------|---------|
| **個別JSON** | 250 MB | 0.5 ms | 5秒 |
| **SQLite** | 180 MB | 0.3 ms | 50 ms |
| **PostgreSQL** | 150 MB | 0.2 ms | 10 ms |

**推奨:** 10,000個規模では **SQLite** が最適

---

## 7. 次のステップ

1. **source_id の決定**
   - Gaia SOURCE_ID推奨
   - または独自のIDスキーム
   
2. **座標情報の取得**
   - カタログからra, decを取得
   
3. **データ変換**
   - 上記スクリプトで推奨形式に変換
   
4. **SQLite移行**（10,000個以上の場合）
   - 上記スキーマとスクリプトを使用

ご不明な点があればお知らせください。
