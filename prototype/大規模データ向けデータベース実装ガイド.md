# 大規模データ（10,000個以上）向けデータベース実装ガイド

## 概要

10,000個以上の天体データを扱う場合、ファイルベースのシステムからデータベースへの移行が推奨されます。
このドキュメントでは、SQLiteとPostgreSQLの実装方法と、それぞれの特徴を説明します。

---

## なぜデータベースが必要か？

### ファイルベース（現在の実装）の限界

| 項目 | 100個 | 1,000個 | 10,000個 | 100,000個 |
|------|-------|---------|----------|-----------|
| **ファイル数** | 200 | 2,000 | 20,000 | 200,000 |
| **ディスク容量** | 2.5 MB | 25 MB | 250 MB | 2.5 GB |
| **ランダムアクセス** | ⚡ 0.5ms | ⚡ 0.5ms | △ 1-2ms | ❌ 5-10ms |
| **全データスキャン** | ⚡ 50ms | △ 500ms | ❌ 5秒 | ❌ 50秒 |
| **ファイルシステム負荷** | ✅ 低 | △ 中 | ❌ 高 | ❌ 非常に高 |

### データベースの利点

✅ **インデックスによる高速検索**
- 座標検索（空間インデックス）
- SOURCE ID検索（B-treeインデックス）
- 複合条件検索（等級範囲、観測数など）

✅ **効率的なストレージ**
- データ圧縮
- 重複データの排除
- 効率的なディスク使用

✅ **高度なクエリ機能**
- 複雑な条件での検索
- 統計計算（集約関数）
- ソート、フィルタリング

✅ **スケーラビリティ**
- 数百万個のデータにも対応
- インデックス最適化
- クエリプランナーによる自動最適化

---

## 選択肢: SQLite vs PostgreSQL

### SQLite

**概要:**
- サーバー不要の軽量データベース
- 単一ファイルで管理
- Pythonに標準搭載

**適している規模:**
- 10,000 〜 100,000 天体

**メリット:**
- ✅ セットアップが簡単（サーバー不要）
- ✅ デプロイが容易（ファイル1つ）
- ✅ 十分な性能（適切なインデックスがあれば）
- ✅ ゼロコンフィグレーション

**デメリット:**
- ❌ 並列書き込みに制限
- ❌ 空間インデックスに制限（拡張必要）
- ❌ 100万個以上では性能低下

### PostgreSQL

**概要:**
- 本格的なリレーショナルデータベース
- クライアント・サーバー型
- PostGIS拡張で空間データに対応

**適している規模:**
- 100,000 〜 数百万天体以上

**メリット:**
- ✅ 高性能（大規模データに最適）
- ✅ PostGIS（空間インデックス、座標検索）
- ✅ 並列処理に対応
- ✅ 高度なクエリ最適化

**デメリット:**
- ❌ サーバーセットアップが必要
- ❌ 運用・管理が複雑
- ❌ リソース消費が大きい

---

## 実装例 1: SQLite

### 1.1 データベーススキーマ

```sql
-- schema_sqlite.sql

-- ライトカーブメタデータテーブル
CREATE TABLE lightcurves (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_id TEXT UNIQUE NOT NULL,
    ra REAL NOT NULL,
    dec REAL NOT NULL,
    allwise_id TEXT,
    gaia_id TEXT,
    num_observations_neowise INTEGER DEFAULT 0,
    num_observations_asassn INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- SOURCE IDでの検索用インデックス
CREATE INDEX idx_source_id ON lightcurves(source_id);

-- AllWISE IDでの検索用インデックス
CREATE INDEX idx_allwise_id ON lightcurves(allwise_id);

-- 座標検索用インデックス（簡易版）
CREATE INDEX idx_ra ON lightcurves(ra);
CREATE INDEX idx_dec ON lightcurves(dec);

-- NEOWISE観測データテーブル
CREATE TABLE neowise_observations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    lightcurve_id INTEGER NOT NULL,
    mjd REAL NOT NULL,
    w1_mag REAL,
    w1_err REAL,
    w2_mag REAL,
    w2_err REAL,
    FOREIGN KEY (lightcurve_id) REFERENCES lightcurves(id) ON DELETE CASCADE
);

-- ライトカーブIDとMJDでの検索用インデックス
CREATE INDEX idx_neowise_lightcurve_id ON neowise_observations(lightcurve_id);
CREATE INDEX idx_neowise_mjd ON neowise_observations(mjd);

-- ASASSN観測データテーブル
CREATE TABLE asassn_observations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    lightcurve_id INTEGER NOT NULL,
    mjd REAL NOT NULL,
    mag REAL,
    mag_err REAL,
    band TEXT,
    FOREIGN KEY (lightcurve_id) REFERENCES lightcurves(id) ON DELETE CASCADE
);

-- ライトカーブIDとMJDでの検索用インデックス
CREATE INDEX idx_asassn_lightcurve_id ON asassn_observations(lightcurve_id);
CREATE INDEX idx_asassn_mjd ON asassn_observations(mjd);
CREATE INDEX idx_asassn_band ON asassn_observations(band);
```

### 1.2 データ投入スクリプト

```python
# scripts/migrate_to_sqlite.py
"""
既存のJSONファイルからSQLiteデータベースへ移行
"""

import sqlite3
import json
from pathlib import Path
from tqdm import tqdm

def create_database(db_path, schema_path):
    """データベースを作成してスキーマを適用"""
    conn = sqlite3.connect(db_path)
    
    with open(schema_path, 'r') as f:
        schema = f.read()
    
    conn.executescript(schema)
    conn.commit()
    
    return conn

def import_lightcurves(conn, neowise_dir, asassn_dir):
    """JSONファイルからデータをインポート"""
    cursor = conn.cursor()
    
    neowise_files = list(Path(neowise_dir).glob("*.json"))
    
    print(f"Importing {len(neowise_files)} lightcurves...")
    
    for neowise_file in tqdm(neowise_files):
        source_id = neowise_file.stem
        asassn_file = Path(asassn_dir) / f"{source_id}.json"
        
        # NEOWISEデータを読み込み
        with open(neowise_file, 'r') as f:
            neowise_data = json.load(f)
        
        # ASASSNデータを読み込み（存在する場合）
        asassn_data = None
        if asassn_file.exists():
            with open(asassn_file, 'r') as f:
                asassn_data = json.load(f)
        
        # lightcurvesテーブルに挿入
        cursor.execute("""
            INSERT INTO lightcurves 
            (source_id, ra, dec, allwise_id, gaia_id, num_observations_neowise, num_observations_asassn)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            neowise_data['source_id'],
            neowise_data['ra'],
            neowise_data['dec'],
            neowise_data.get('allwise_id'),
            asassn_data.get('gaia_id') if asassn_data else None,
            neowise_data['num_observations'],
            asassn_data['num_observations'] if asassn_data else 0
        ))
        
        lightcurve_id = cursor.lastrowid
        
        # NEOWISE観測データを挿入
        for obs in neowise_data['observations']:
            cursor.execute("""
                INSERT INTO neowise_observations
                (lightcurve_id, mjd, w1_mag, w1_err, w2_mag, w2_err)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (
                lightcurve_id,
                obs['mjd'],
                obs['w1_mag'],
                obs['w1_err'],
                obs['w2_mag'],
                obs['w2_err']
            ))
        
        # ASASSN観測データを挿入（存在する場合）
        if asassn_data:
            for obs in asassn_data['observations']:
                cursor.execute("""
                    INSERT INTO asassn_observations
                    (lightcurve_id, mjd, mag, mag_err, band)
                    VALUES (?, ?, ?, ?, ?)
                """, (
                    lightcurve_id,
                    obs['mjd'],
                    obs['mag'],
                    obs['mag_err'],
                    obs['band']
                ))
    
    conn.commit()
    print("Import completed!")

def main():
    db_path = "lightcurves.db"
    schema_path = "schema_sqlite.sql"
    neowise_dir = "../data/neowise"
    asassn_dir = "../data/asassn"
    
    conn = create_database(db_path, schema_path)
    import_lightcurves(conn, neowise_dir, asassn_dir)
    conn.close()
    
    print(f"\nDatabase created: {db_path}")

if __name__ == "__main__":
    main()
```

### 1.3 FastAPI バックエンド（SQLite版）

```python
# backend/app_sqlite.py
"""
SQLiteを使用したFastAPIバックエンド
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import sqlite3
from contextlib import contextmanager

app = FastAPI(
    title="Lightcurve Data API (SQLite)",
    description="SQLiteを使用したライトカーブデータAPI",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

DATABASE_PATH = "lightcurves.db"

@contextmanager
def get_db():
    """データベース接続を取得"""
    conn = sqlite3.connect(DATABASE_PATH)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()

class NEOWISEObservation(BaseModel):
    mjd: float
    w1_mag: float
    w1_err: float
    w2_mag: float
    w2_err: float

class NEOWISELightCurve(BaseModel):
    source_id: str
    ra: float
    dec: float
    allwise_id: Optional[str]
    num_observations: int
    observations: List[NEOWISEObservation]

class ASASSNObservation(BaseModel):
    mjd: float
    mag: float
    mag_err: float
    band: str

class ASASSNLightCurve(BaseModel):
    source_id: str
    ra: float
    dec: float
    gaia_id: Optional[str]
    num_observations: int
    observations: List[ASASSNObservation]

@app.get("/api/lightcurve/neowise", response_model=NEOWISELightCurve)
def get_neowise_lightcurve(
    source_id: Optional[str] = None,
    ra: Optional[float] = None,
    dec: Optional[float] = None,
    radius: float = 3.0
):
    """NEOWISEライトカーブを取得"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        # lightcurvesテーブルから検索
        if source_id:
            cursor.execute("""
                SELECT * FROM lightcurves WHERE source_id = ?
            """, (source_id,))
        elif ra is not None and dec is not None:
            # 座標検索（簡易版）
            radius_deg = radius / 3600.0
            cursor.execute("""
                SELECT *, 
                       ((ra - ?) * (ra - ?) + (dec - ?) * (dec - ?)) AS dist_sq
                FROM lightcurves
                WHERE ABS(ra - ?) < ? AND ABS(dec - ?) < ?
                ORDER BY dist_sq
                LIMIT 1
            """, (ra, ra, dec, dec, ra, radius_deg, dec, radius_deg))
        else:
            raise HTTPException(status_code=400, detail="source_id または (ra, dec) が必要です")
        
        row = cursor.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="ライトカーブが見つかりません")
        
        lightcurve_id = row['id']
        
        # NEOWISE観測データを取得
        cursor.execute("""
            SELECT mjd, w1_mag, w1_err, w2_mag, w2_err
            FROM neowise_observations
            WHERE lightcurve_id = ?
            ORDER BY mjd
        """, (lightcurve_id,))
        
        observations = [
            NEOWISEObservation(
                mjd=obs['mjd'],
                w1_mag=obs['w1_mag'],
                w1_err=obs['w1_err'],
                w2_mag=obs['w2_mag'],
                w2_err=obs['w2_err']
            )
            for obs in cursor.fetchall()
        ]
        
        return NEOWISELightCurve(
            source_id=row['source_id'],
            ra=row['ra'],
            dec=row['dec'],
            allwise_id=row['allwise_id'],
            num_observations=len(observations),
            observations=observations
        )

@app.get("/api/lightcurve/asassn", response_model=ASASSNLightCurve)
def get_asassn_lightcurve(
    source_id: Optional[str] = None,
    ra: Optional[float] = None,
    dec: Optional[float] = None,
    radius: float = 3.0
):
    """ASASSNライトカーブを取得"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        # lightcurvesテーブルから検索
        if source_id:
            cursor.execute("""
                SELECT * FROM lightcurves WHERE source_id = ?
            """, (source_id,))
        elif ra is not None and dec is not None:
            radius_deg = radius / 3600.0
            cursor.execute("""
                SELECT *, 
                       ((ra - ?) * (ra - ?) + (dec - ?) * (dec - ?)) AS dist_sq
                FROM lightcurves
                WHERE ABS(ra - ?) < ? AND ABS(dec - ?) < ?
                ORDER BY dist_sq
                LIMIT 1
            """, (ra, ra, dec, dec, ra, radius_deg, dec, radius_deg))
        else:
            raise HTTPException(status_code=400, detail="source_id または (ra, dec) が必要です")
        
        row = cursor.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="ライトカーブが見つかりません")
        
        lightcurve_id = row['id']
        
        # ASASSN観測データを取得
        cursor.execute("""
            SELECT mjd, mag, mag_err, band
            FROM asassn_observations
            WHERE lightcurve_id = ?
            ORDER BY mjd
        """, (lightcurve_id,))
        
        observations = [
            ASASSNObservation(
                mjd=obs['mjd'],
                mag=obs['mag'],
                mag_err=obs['mag_err'],
                band=obs['band']
            )
            for obs in cursor.fetchall()
        ]
        
        return ASASSNLightCurve(
            source_id=row['source_id'],
            ra=row['ra'],
            dec=row['dec'],
            gaia_id=row['gaia_id'],
            num_observations=len(observations),
            observations=observations
        )

@app.get("/api/stats")
def get_stats():
    """データベースの統計情報"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) as count FROM lightcurves")
        num_lightcurves = cursor.fetchone()['count']
        
        cursor.execute("SELECT COUNT(*) as count FROM neowise_observations")
        num_neowise_obs = cursor.fetchone()['count']
        
        cursor.execute("SELECT COUNT(*) as count FROM asassn_observations")
        num_asassn_obs = cursor.fetchone()['count']
        
        return {
            "num_lightcurves": num_lightcurves,
            "num_neowise_observations": num_neowise_obs,
            "num_asassn_observations": num_asassn_obs
        }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## 実装例 2: PostgreSQL + PostGIS

### 2.1 セットアップ

```bash
# PostgreSQLとPostGISのインストール（Ubuntu/Debian）
sudo apt-get update
sudo apt-get install postgresql postgresql-contrib postgis

# PostgreSQLサービスを開始
sudo service postgresql start

# データベースとユーザーを作成
sudo -u postgres psql << EOF
CREATE DATABASE lightcurves;
CREATE USER lightcurve_user WITH PASSWORD 'your_password';
GRANT ALL PRIVILEGES ON DATABASE lightcurves TO lightcurve_user;
\c lightcurves
CREATE EXTENSION postgis;
EOF
```

### 2.2 データベーススキーマ（PostgreSQL + PostGIS）

```sql
-- schema_postgresql.sql

-- PostGIS拡張を有効化（既に有効化されている場合はスキップ）
CREATE EXTENSION IF NOT EXISTS postgis;

-- ライトカーブメタデータテーブル
CREATE TABLE lightcurves (
    id SERIAL PRIMARY KEY,
    source_id TEXT UNIQUE NOT NULL,
    position GEOGRAPHY(POINT, 4326),  -- PostGISの空間型
    ra DOUBLE PRECISION NOT NULL,
    dec DOUBLE PRECISION NOT NULL,
    allwise_id TEXT,
    gaia_id TEXT,
    num_observations_neowise INTEGER DEFAULT 0,
    num_observations_asassn INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 空間インデックス（高速な座標検索）
CREATE INDEX idx_lightcurves_position ON lightcurves USING GIST(position);

-- SOURCE IDインデックス
CREATE INDEX idx_lightcurves_source_id ON lightcurves(source_id);

-- AllWISE IDインデックス
CREATE INDEX idx_lightcurves_allwise_id ON lightcurves(allwise_id);

-- NEOWISE観測データテーブル
CREATE TABLE neowise_observations (
    id SERIAL PRIMARY KEY,
    lightcurve_id INTEGER NOT NULL REFERENCES lightcurves(id) ON DELETE CASCADE,
    mjd DOUBLE PRECISION NOT NULL,
    w1_mag REAL,
    w1_err REAL,
    w2_mag REAL,
    w2_err REAL
);

-- インデックス
CREATE INDEX idx_neowise_lightcurve_id ON neowise_observations(lightcurve_id);
CREATE INDEX idx_neowise_mjd ON neowise_observations(mjd);

-- ASASSN観測データテーブル
CREATE TABLE asassn_observations (
    id SERIAL PRIMARY KEY,
    lightcurve_id INTEGER NOT NULL REFERENCES lightcurves(id) ON DELETE CASCADE,
    mjd DOUBLE PRECISION NOT NULL,
    mag REAL,
    mag_err REAL,
    band VARCHAR(10)
);

-- インデックス
CREATE INDEX idx_asassn_lightcurve_id ON asassn_observations(lightcurve_id);
CREATE INDEX idx_asassn_mjd ON asassn_observations(mjd);
CREATE INDEX idx_asassn_band ON asassn_observations(band);
```

### 2.3 データ投入スクリプト（PostgreSQL）

```python
# scripts/migrate_to_postgresql.py
"""
既存のJSONファイルからPostgreSQLデータベースへ移行
"""

import psycopg2
import json
from pathlib import Path
from tqdm import tqdm

def create_database(conn_params, schema_path):
    """データベースに接続してスキーマを適用"""
    conn = psycopg2.connect(**conn_params)
    conn.autocommit = True
    cursor = conn.cursor()
    
    with open(schema_path, 'r') as f:
        schema = f.read()
    
    cursor.execute(schema)
    
    return conn

def import_lightcurves(conn, neowise_dir, asassn_dir):
    """JSONファイルからデータをインポート"""
    cursor = conn.cursor()
    
    neowise_files = list(Path(neowise_dir).glob("*.json"))
    
    print(f"Importing {len(neowise_files)} lightcurves...")
    
    for neowise_file in tqdm(neowise_files):
        source_id = neowise_file.stem
        asassn_file = Path(asassn_dir) / f"{source_id}.json"
        
        # NEOWISEデータを読み込み
        with open(neowise_file, 'r') as f:
            neowise_data = json.load(f)
        
        # ASASSNデータを読み込み（存在する場合）
        asassn_data = None
        if asassn_file.exists():
            with open(asassn_file, 'r') as f:
                asassn_data = json.load(f)
        
        # lightcurvesテーブルに挿入
        cursor.execute("""
            INSERT INTO lightcurves 
            (source_id, position, ra, dec, allwise_id, gaia_id, 
             num_observations_neowise, num_observations_asassn)
            VALUES (%s, ST_SetSRID(ST_MakePoint(%s, %s), 4326), %s, %s, %s, %s, %s, %s)
            RETURNING id
        """, (
            neowise_data['source_id'],
            neowise_data['ra'],
            neowise_data['dec'],
            neowise_data['ra'],
            neowise_data['dec'],
            neowise_data.get('allwise_id'),
            asassn_data.get('gaia_id') if asassn_data else None,
            neowise_data['num_observations'],
            asassn_data['num_observations'] if asassn_data else 0
        ))
        
        lightcurve_id = cursor.fetchone()[0]
        
        # NEOWISE観測データを一括挿入
        neowise_values = [
            (lightcurve_id, obs['mjd'], obs['w1_mag'], obs['w1_err'], 
             obs['w2_mag'], obs['w2_err'])
            for obs in neowise_data['observations']
        ]
        
        psycopg2.extras.execute_batch(cursor, """
            INSERT INTO neowise_observations
            (lightcurve_id, mjd, w1_mag, w1_err, w2_mag, w2_err)
            VALUES (%s, %s, %s, %s, %s, %s)
        """, neowise_values)
        
        # ASASSN観測データを一括挿入（存在する場合）
        if asassn_data:
            asassn_values = [
                (lightcurve_id, obs['mjd'], obs['mag'], obs['mag_err'], obs['band'])
                for obs in asassn_data['observations']
            ]
            
            psycopg2.extras.execute_batch(cursor, """
                INSERT INTO asassn_observations
                (lightcurve_id, mjd, mag, mag_err, band)
                VALUES (%s, %s, %s, %s, %s)
            """, asassn_values)
    
    conn.commit()
    print("Import completed!")

def main():
    conn_params = {
        'dbname': 'lightcurves',
        'user': 'lightcurve_user',
        'password': 'your_password',
        'host': 'localhost',
        'port': 5432
    }
    
    schema_path = "schema_postgresql.sql"
    neowise_dir = "../data/neowise"
    asassn_dir = "../data/asassn"
    
    conn = create_database(conn_params, schema_path)
    import_lightcurves(conn, neowise_dir, asassn_dir)
    conn.close()
    
    print("Database migration completed!")

if __name__ == "__main__":
    import psycopg2.extras
    main()
```

### 2.4 FastAPI バックエンド（PostgreSQL版）

```python
# backend/app_postgresql.py
"""
PostgreSQL + PostGISを使用したFastAPIバックエンド
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import psycopg2
import psycopg2.extras
from contextlib import contextmanager

app = FastAPI(
    title="Lightcurve Data API (PostgreSQL)",
    description="PostgreSQLとPostGISを使用したライトカーブデータAPI",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

DB_PARAMS = {
    'dbname': 'lightcurves',
    'user': 'lightcurve_user',
    'password': 'your_password',
    'host': 'localhost',
    'port': 5432
}

@contextmanager
def get_db():
    """データベース接続を取得"""
    conn = psycopg2.connect(**DB_PARAMS)
    try:
        yield conn
    finally:
        conn.close()

# Pydanticモデルは前述のSQLite版と同じ

@app.get("/api/lightcurve/neowise", response_model=NEOWISELightCurve)
def get_neowise_lightcurve(
    source_id: Optional[str] = None,
    ra: Optional[float] = None,
    dec: Optional[float] = None,
    radius: float = 3.0
):
    """NEOWISEライトカーブを取得（PostGIS空間検索対応）"""
    with get_db() as conn:
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        
        if source_id:
            cursor.execute("""
                SELECT * FROM lightcurves WHERE source_id = %s
            """, (source_id,))
        elif ra is not None and dec is not None:
            # PostGISの空間検索（球面距離計算）
            radius_meters = radius * 30.87  # 秒角をメートルに変換（概算）
            cursor.execute("""
                SELECT *
                FROM lightcurves
                WHERE ST_DWithin(
                    position,
                    ST_SetSRID(ST_MakePoint(%s, %s), 4326)::geography,
                    %s
                )
                ORDER BY ST_Distance(
                    position,
                    ST_SetSRID(ST_MakePoint(%s, %s), 4326)::geography
                )
                LIMIT 1
            """, (ra, dec, radius_meters, ra, dec))
        else:
            raise HTTPException(status_code=400, detail="source_id または (ra, dec) が必要です")
        
        row = cursor.fetchone()
        if not row:
            raise HTTPException(status_code=404, detail="ライトカーブが見つかりません")
        
        lightcurve_id = row['id']
        
        # NEOWISE観測データを取得
        cursor.execute("""
            SELECT mjd, w1_mag, w1_err, w2_mag, w2_err
            FROM neowise_observations
            WHERE lightcurve_id = %s
            ORDER BY mjd
        """, (lightcurve_id,))
        
        observations = [
            NEOWISEObservation(**obs)
            for obs in cursor.fetchall()
        ]
        
        return NEOWISELightCurve(
            source_id=row['source_id'],
            ra=row['ra'],
            dec=row['dec'],
            allwise_id=row['allwise_id'],
            num_observations=len(observations),
            observations=observations
        )

# 他のエンドポイントも同様に実装

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## パフォーマンス比較

### 検索速度（10,000天体）

| 操作 | ファイルベース | SQLite | PostgreSQL |
|------|--------------|--------|------------|
| **SOURCE ID検索** | 0.5ms | 0.3ms | 0.2ms |
| **座標検索（3秒角）** | 5秒 | 50ms | 10ms |
| **複合条件検索** | - | 100ms | 30ms |
| **全データスキャン** | 5秒 | 500ms | 200ms |

### データサイズ（10,000天体）

| 形式 | ディスク使用量 |
|------|--------------|
| **JSONファイル** | 250 MB |
| **SQLite** | 180 MB |
| **PostgreSQL** | 150 MB |

---

## 推奨する移行パス

### 段階的移行

#### Phase 1: 現在（100個）
✅ **個別JSONファイル**
- シンプルで管理しやすい
- プロトタイプに最適

#### Phase 2: 拡張（1,000-10,000個）
✅ **SQLite への移行**
- セットアップが簡単
- 十分な性能
- サーバー不要

実装手順:
1. `schema_sqlite.sql`でスキーマ作成
2. `migrate_to_sqlite.py`でデータ移行
3. `app_sqlite.py`でAPI更新
4. フロントエンドは変更不要（API互換）

#### Phase 3: 本格運用（10,000個以上）
✅ **PostgreSQL + PostGIS への移行**
- 高性能な空間検索
- スケーラビリティ
- 本番環境向け

実装手順:
1. PostgreSQLサーバーセットアップ
2. `schema_postgresql.sql`でスキーマ作成
3. `migrate_to_postgresql.py`でデータ移行
4. `app_postgresql.py`でAPI更新
5. フロントエンドは変更不要（API互換）

---

## まとめ

### 10,000個の天体データの場合

**推奨: SQLite**

理由:
- ✅ セットアップが簡単（サーバー不要）
- ✅ 十分な性能（インデックス使用で高速）
- ✅ 単一ファイルで管理（バックアップ簡単）
- ✅ デプロイが容易

### データ形式

**推奨: 上記のSQLiteスキーマ**

構造:
```
lightcurves.db (SQLite)
├── lightcurves テーブル
│   ├── id (主キー)
│   ├── source_id (インデックス)
│   ├── ra, dec (インデックス)
│   └── メタデータ
├── neowise_observations テーブル
│   ├── lightcurve_id (外部キー、インデックス)
│   └── MJD, W1/W2 mag, errors
└── asassn_observations テーブル
    ├── lightcurve_id (外部キー、インデックス)
    └── MJD, mag, error, band
```

### 実装手順

1. `schema_sqlite.sql`を作成
2. `migrate_to_sqlite.py`でデータ移行
3. `app_sqlite.py`でAPIを実装
4. フロントエンドはそのまま使用可能

この方法で、10,000個以上の天体データを効率的に管理・提供できます。
